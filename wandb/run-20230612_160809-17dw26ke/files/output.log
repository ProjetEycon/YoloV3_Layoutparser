Namespace(epochs=20, image_folder='data/artifacts/images', batch_size=1, model_config_path='config/yolov3.cfg', data_config_path='config/coco.data', weights_path='config/yolov3.weights', class_path='config/coco.names', conf_thres=0.8, nms_thres=0.4, n_cpu=0, img_size=2300, checkpoint_interval=1, checkpoint_dir='checkpoints', use_cuda=True)
True
init du model
model done
Darknet(
  (module_list): ModuleList(
    (0): Sequential(
      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_0): LeakyReLU(negative_slope=0.1)
    )
    (1): Sequential(
      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_1): LeakyReLU(negative_slope=0.1)
    )
    (2): Sequential(
      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_2): LeakyReLU(negative_slope=0.1)
    )
    (3): Sequential(
      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_3): LeakyReLU(negative_slope=0.1)
    )
    (4): Sequential(
      (shortcut_4): EmptyLayer()
    )
    (5): Sequential(
      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_5): LeakyReLU(negative_slope=0.1)
    )
    (6): Sequential(
      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_6): LeakyReLU(negative_slope=0.1)
    )
    (7): Sequential(
      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_7): LeakyReLU(negative_slope=0.1)
    )
    (8): Sequential(
      (shortcut_8): EmptyLayer()
    )
    (9): Sequential(
      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_9): LeakyReLU(negative_slope=0.1)
    )
    (10): Sequential(
      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_10): LeakyReLU(negative_slope=0.1)
    )
    (11): Sequential(
      (shortcut_11): EmptyLayer()
    )
    (12): Sequential(
      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_12): LeakyReLU(negative_slope=0.1)
    )
    (13): Sequential(
      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_13): LeakyReLU(negative_slope=0.1)
    )
    (14): Sequential(
      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_14): LeakyReLU(negative_slope=0.1)
    )
    (15): Sequential(
      (shortcut_15): EmptyLayer()
    )
    (16): Sequential(
      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_16): LeakyReLU(negative_slope=0.1)
    )
    (17): Sequential(
      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_17): LeakyReLU(negative_slope=0.1)
    )
    (18): Sequential(
      (shortcut_18): EmptyLayer()
    )
    (19): Sequential(
      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_19): LeakyReLU(negative_slope=0.1)
    )
    (20): Sequential(
      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_20): LeakyReLU(negative_slope=0.1)
    )
    (21): Sequential(
      (shortcut_21): EmptyLayer()
    )
    (22): Sequential(
      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_22): LeakyReLU(negative_slope=0.1)
    )
    (23): Sequential(
      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_23): LeakyReLU(negative_slope=0.1)
    )
    (24): Sequential(
      (shortcut_24): EmptyLayer()
    )
    (25): Sequential(
      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_25): LeakyReLU(negative_slope=0.1)
    )
    (26): Sequential(
      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_26): LeakyReLU(negative_slope=0.1)
    )
    (27): Sequential(
      (shortcut_27): EmptyLayer()
    )
    (28): Sequential(
      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_28): LeakyReLU(negative_slope=0.1)
    )
    (29): Sequential(
      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_29): LeakyReLU(negative_slope=0.1)
    )
    (30): Sequential(
      (shortcut_30): EmptyLayer()
    )
    (31): Sequential(
      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_31): LeakyReLU(negative_slope=0.1)
    )
    (32): Sequential(
      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_32): LeakyReLU(negative_slope=0.1)
    )
    (33): Sequential(
      (shortcut_33): EmptyLayer()
    )
    (34): Sequential(
      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_34): LeakyReLU(negative_slope=0.1)
    )
    (35): Sequential(
      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_35): LeakyReLU(negative_slope=0.1)
    )
    (36): Sequential(
      (shortcut_36): EmptyLayer()
    )
    (37): Sequential(
      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_37): LeakyReLU(negative_slope=0.1)
    )
    (38): Sequential(
      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_38): LeakyReLU(negative_slope=0.1)
    )
    (39): Sequential(
      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_39): LeakyReLU(negative_slope=0.1)
    )
    (40): Sequential(
      (shortcut_40): EmptyLayer()
    )
    (41): Sequential(
      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_41): LeakyReLU(negative_slope=0.1)
    )
    (42): Sequential(
      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_42): LeakyReLU(negative_slope=0.1)
    )
    (43): Sequential(
      (shortcut_43): EmptyLayer()
    )
    (44): Sequential(
      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_44): LeakyReLU(negative_slope=0.1)
    )
    (45): Sequential(
      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_45): LeakyReLU(negative_slope=0.1)
    )
    (46): Sequential(
      (shortcut_46): EmptyLayer()
    )
    (47): Sequential(
      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_47): LeakyReLU(negative_slope=0.1)
    )
    (48): Sequential(
      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_48): LeakyReLU(negative_slope=0.1)
    )
    (49): Sequential(
      (shortcut_49): EmptyLayer()
    )
    (50): Sequential(
      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_50): LeakyReLU(negative_slope=0.1)
    )
    (51): Sequential(
      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_51): LeakyReLU(negative_slope=0.1)
    )
    (52): Sequential(
      (shortcut_52): EmptyLayer()
    )
    (53): Sequential(
      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_53): LeakyReLU(negative_slope=0.1)
    )
    (54): Sequential(
      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_54): LeakyReLU(negative_slope=0.1)
    )
    (55): Sequential(
      (shortcut_55): EmptyLayer()
    )
    (56): Sequential(
      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_56): LeakyReLU(negative_slope=0.1)
    )
    (57): Sequential(
      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_57): LeakyReLU(negative_slope=0.1)
    )
    (58): Sequential(
      (shortcut_58): EmptyLayer()
    )
    (59): Sequential(
      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_59): LeakyReLU(negative_slope=0.1)
    )
    (60): Sequential(
      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_60): LeakyReLU(negative_slope=0.1)
    )
    (61): Sequential(
      (shortcut_61): EmptyLayer()
    )
    (62): Sequential(
      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_62): LeakyReLU(negative_slope=0.1)
    )
    (63): Sequential(
      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_63): LeakyReLU(negative_slope=0.1)
    )
    (64): Sequential(
      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_64): LeakyReLU(negative_slope=0.1)
    )
    (65): Sequential(
      (shortcut_65): EmptyLayer()
    )
    (66): Sequential(
      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_66): LeakyReLU(negative_slope=0.1)
    )
    (67): Sequential(
      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_67): LeakyReLU(negative_slope=0.1)
    )
    (68): Sequential(
      (shortcut_68): EmptyLayer()
    )
    (69): Sequential(
      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_69): LeakyReLU(negative_slope=0.1)
    )
    (70): Sequential(
      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_70): LeakyReLU(negative_slope=0.1)
    )
    (71): Sequential(
      (shortcut_71): EmptyLayer()
    )
    (72): Sequential(
      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_72): LeakyReLU(negative_slope=0.1)
    )
    (73): Sequential(
      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_73): LeakyReLU(negative_slope=0.1)
    )
    (74): Sequential(
      (shortcut_74): EmptyLayer()
    )
    (75): Sequential(
      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_75): LeakyReLU(negative_slope=0.1)
    )
    (76): Sequential(
      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_76): LeakyReLU(negative_slope=0.1)
    )
    (77): Sequential(
      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_77): LeakyReLU(negative_slope=0.1)
    )
    (78): Sequential(
      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_78): LeakyReLU(negative_slope=0.1)
    )
    (79): Sequential(
      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_79): LeakyReLU(negative_slope=0.1)
    )
    (80): Sequential(
      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_80): LeakyReLU(negative_slope=0.1)
    )
    (81): Sequential(
      (conv_81): Conv2d(1024, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (82): Sequential(
      (yolo_82): YOLOLayer(
        (mse_loss): MSELoss()
        (bce_loss): BCEWithLogitsLoss()
        (ce_loss): CrossEntropyLoss()
      )
    )
    (83): Sequential(
      (route_83): EmptyLayer()
    )
    (84): Sequential(
      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_84): LeakyReLU(negative_slope=0.1)
    )
    (85): Sequential(
      (upsample_85): Upsample(scale_factor=2.0, mode='nearest')
    )
    (86): Sequential(
      (route_86): EmptyLayer()
    )
    (87): Sequential(
      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_87): LeakyReLU(negative_slope=0.1)
    )
    (88): Sequential(
      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_88): LeakyReLU(negative_slope=0.1)
    )
    (89): Sequential(
      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_89): LeakyReLU(negative_slope=0.1)
    )
    (90): Sequential(
      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_90): LeakyReLU(negative_slope=0.1)
    )
    (91): Sequential(
      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_91): LeakyReLU(negative_slope=0.1)
    )
    (92): Sequential(
      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_92): LeakyReLU(negative_slope=0.1)
    )
    (93): Sequential(
      (conv_93): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (94): Sequential(
      (yolo_94): YOLOLayer(
        (mse_loss): MSELoss()
        (bce_loss): BCEWithLogitsLoss()
        (ce_loss): CrossEntropyLoss()
      )
    )
    (95): Sequential(
      (route_95): EmptyLayer()
    )
    (96): Sequential(
      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_96): LeakyReLU(negative_slope=0.1)
    )
    (97): Sequential(
      (upsample_97): Upsample(scale_factor=2.0, mode='nearest')
    )
    (98): Sequential(
      (route_98): EmptyLayer()
    )
    (99): Sequential(
      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_99): LeakyReLU(negative_slope=0.1)
    )
    (100): Sequential(
      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_100): LeakyReLU(negative_slope=0.1)
    )
    (101): Sequential(
      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_101): LeakyReLU(negative_slope=0.1)
    )
    (102): Sequential(
      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_102): LeakyReLU(negative_slope=0.1)
    )
    (103): Sequential(
      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_103): LeakyReLU(negative_slope=0.1)
    )
    (104): Sequential(
      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_104): LeakyReLU(negative_slope=0.1)
    )
    (105): Sequential(
      (conv_105): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))
    )
    (106): Sequential(
      (yolo_106): YOLOLayer(
        (mse_loss): MSELoss()
        (bce_loss): BCEWithLogitsLoss()
        (ce_loss): CrossEntropyLoss()
      )
    )
  )
)
model.train
C:\Users\salim\Documents\salimev\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
  0%|                                                                                               | 0/24300 [00:00<?, ?it/s]
('D:\\dataset3\\train/np_cesoir_19451102_01.jpg', tensor([[[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         ...,
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],
        [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         ...,
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],
        [[0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         ...,
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],
         [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]), tensor([[  0.0000, 852.9701, 269.2991, 528.6779,  26.0000]],
       dtype=torch.float64))
loader done
debut du training
  0%|                                                                                               | 0/24300 [00:00<?, ?it/s]C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_x = self.mse_loss(x[mask], tx[mask])
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:198: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_y = self.mse_loss(y[mask], ty[mask])
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:199: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_w = self.mse_loss(w[mask], tw[mask])
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:200: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_h = self.mse_loss(h[mask], th[mask])
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:201: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_conf = self.bce_loss(pred_conf[conf_mask_false], tconf[conf_mask_false]) + self.bce_loss(
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:202: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  pred_conf[conf_mask_true], tconf[conf_mask_true]
C:\Users\salim\Documents\pytorch_custom_yolo_training\models.py:204: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\aten\src\ATen/native/IndexingUtils.h:28.)
  loss_cls = (1 / nB) * self.ce_loss(pred_cls[mask], torch.argmax(tcls[mask], 1))
C:\Users\salim\Documents\salimev\lib\site-packages\torch\autograd\__init__.py:200: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src\ATen/native/IndexingUtils.h:28.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  0%|                                                                                    | 1/24300 [00:07<49:03:19,  7.27s/it]
[Epoch 0/20, Batch 0/24300] [Losses: x 0.386315, y 0.370335, w 3.982695, h 9.758870, conf 4.323920, cls 2.866211, total 21.688347, recall: 0.00000, precision: 0.00000]

  0%|                                                                                    | 2/24300 [00:11<37:11:20,  5.51s/it]

  0%|                                                                                    | 3/24300 [00:15<33:13:02,  4.92s/it]


  0%|                                                                                    | 5/24300 [00:23<29:26:13,  4.36s/it]
[Epoch 0/20, Batch 4/24300] [Losses: x 0.138894, y 0.427059, w 80.541200, h 65.255963, conf 4.342832, cls 2.571777, total 153.277725, recall: 0.00000, precision: 0.00000]

  0%|                                                                                    | 6/24300 [00:27<28:35:28,  4.24s/it]

  0%|                                                                                    | 7/24300 [00:31<28:07:13,  4.17s/it]

  0%|                                                                                    | 8/24300 [00:35<27:50:16,  4.13s/it]


  0%|                                                                                   | 10/24300 [00:43<27:25:25,  4.06s/it]

  0%|                                                                                   | 11/24300 [00:47<27:19:20,  4.05s/it]

  0%|                                                                                   | 12/24300 [00:51<26:47:25,  3.97s/it]

  0%|                                                                                   | 13/24300 [00:55<27:19:21,  4.05s/it]

  0%|                                                                                   | 14/24300 [00:59<27:07:53,  4.02s/it]

  0%|                                                                                   | 15/24300 [01:03<27:11:14,  4.03s/it]

  0%|                                                                                   | 16/24300 [01:08<27:59:55,  4.15s/it]

  0%|                                                                                   | 17/24300 [01:12<27:18:44,  4.05s/it]

  0%|                                                                                   | 18/24300 [01:15<26:48:11,  3.97s/it]

  0%|                                                                                   | 19/24300 [01:20<28:07:37,  4.17s/it]

  0%|                                                                                   | 20/24300 [01:24<27:44:35,  4.11s/it]

  0%|                                                                                   | 21/24300 [01:29<29:12:32,  4.33s/it]

  0%|                                                                                   | 22/24300 [01:34<30:35:52,  4.54s/it]

  0%|                                                                                   | 23/24300 [01:38<29:12:01,  4.33s/it]

  0%|                                                                                   | 24/24300 [01:42<28:29:45,  4.23s/it]

  0%|                                                                                   | 25/24300 [01:46<28:05:40,  4.17s/it]

  0%|                                                                                   | 26/24300 [01:50<27:47:38,  4.12s/it]

  0%|                                                                                   | 27/24300 [01:54<28:05:13,  4.17s/it]

  0%|                                                                                   | 28/24300 [01:58<27:41:00,  4.11s/it]

  0%|                                                                                   | 29/24300 [02:02<27:31:51,  4.08s/it]

  0%|                                                                                   | 30/24300 [02:07<28:34:07,  4.24s/it]

  0%|                                                                                   | 31/24300 [02:10<27:45:46,  4.12s/it]

  0%|                                                                                   | 32/24300 [02:14<27:06:57,  4.02s/it]

  0%|                                                                                   | 33/24300 [02:19<27:56:46,  4.15s/it]

  0%|                                                                                   | 34/24300 [02:23<28:27:41,  4.22s/it]

  0%|                                                                                   | 35/24300 [02:27<28:01:43,  4.16s/it]

  0%|                                                                                   | 36/24300 [02:31<28:09:59,  4.18s/it]

  0%|▏                                                                                  | 37/24300 [02:36<29:24:57,  4.36s/it]

  0%|▏                                                                                  | 38/24300 [02:40<28:45:07,  4.27s/it]

  0%|▏                                                                                  | 39/24300 [02:44<27:50:32,  4.13s/it]

  0%|▏                                                                                  | 40/24300 [02:48<28:23:40,  4.21s/it]

  0%|▏                                                                                  | 41/24300 [02:53<28:47:26,  4.27s/it]

  0%|▏                                                                                  | 42/24300 [02:57<28:16:51,  4.20s/it]

  0%|▏                                                                                  | 43/24300 [03:01<27:32:11,  4.09s/it]

  0%|▏                                                                                  | 44/24300 [03:05<27:23:31,  4.07s/it]

  0%|▏                                                                                  | 45/24300 [03:08<26:51:43,  3.99s/it]

  0%|▏                                                                                  | 46/24300 [03:13<28:08:43,  4.18s/it]

  0%|▏                                                                                  | 47/24300 [03:17<27:49:06,  4.13s/it]
[Epoch 0/20, Batch 46/24300] [Losses: x 0.182002, y 0.160391, w 0.440217, h 1.105502, conf 4.034985, cls 1.772461, total 7.695558, recall: 0.66667, precision: 0.00012]


  0%|▏                                                                                  | 49/24300 [03:26<28:32:04,  4.24s/it]

  0%|▏                                                                                  | 50/24300 [03:31<29:44:20,  4.41s/it]

  0%|▏                                                                                  | 51/24300 [03:35<28:53:48,  4.29s/it]

  0%|▏                                                                                  | 52/24300 [03:39<28:21:32,  4.21s/it]

  0%|▏                                                                                  | 53/24300 [03:43<28:45:47,  4.27s/it]

  0%|▏                                                                                  | 54/24300 [03:47<28:37:23,  4.25s/it]

  0%|▏                                                                                  | 55/24300 [03:52<29:24:02,  4.37s/it]

  0%|▏                                                                                  | 56/24300 [03:56<29:08:32,  4.33s/it]

  0%|▏                                                                                  | 57/24300 [04:01<29:40:54,  4.41s/it]

  0%|▏                                                                                  | 58/24300 [04:05<29:42:43,  4.41s/it]

  0%|▏                                                                                  | 59/24300 [04:10<30:05:12,  4.47s/it]

  0%|▏                                                                                  | 60/24300 [04:14<29:34:27,  4.39s/it]

  0%|▏                                                                                  | 61/24300 [04:19<30:05:01,  4.47s/it]

  0%|▏                                                                                  | 62/24300 [04:23<30:47:34,  4.57s/it]

  0%|▏                                                                                  | 63/24300 [04:28<30:52:00,  4.58s/it]

  0%|▏                                                                                  | 64/24300 [04:32<30:33:35,  4.54s/it]

  0%|▏                                                                                  | 65/24300 [04:37<30:41:45,  4.56s/it]

  0%|▏                                                                                  | 66/24300 [04:42<30:47:30,  4.57s/it]

  0%|▏                                                                                  | 67/24300 [04:47<31:18:46,  4.65s/it]
